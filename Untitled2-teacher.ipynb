{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fbde54ac-81a1-4041-ad71-03a61ff2f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "import torchdata\n",
    "import warnings \n",
    "from torchtext.data.utils import get_tokenizer        # 分词工具\n",
    "from torchtext.vocab import build_vocab_from_iterator # 创建此表工具 \n",
    "from torchtext.data.functional import to_map_style_dataset  # 制作数据集\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.optim import lr_scheduler\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df25d092-2d6a-4989-a818-c415c36ec78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter,test_iter = torchtext.datasets.IMDB(root=\"./data\",split=('train', 'test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f08c5328-2665-4e52-bdd5-a6d93bce9359",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = set([label for (label,text) in test_iter])\n",
    "num_class = len(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7f70e04-d0bc-486f-b23b-c4d47bf1583d",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 分词 \n",
    "tokenizer = get_tokenizer('basic_english')   # 初始化分词工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd577633-d2d3-417e-9f84-85675498e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作此表\n",
    "# 定义一个生成器，返回分词之后的文本\n",
    "def yield_tokens(data):\n",
    "    for _,text in data:\n",
    "        yield tokenizer(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef0ff32d-a9ed-42fc-965c-83b5ef4ea2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建此表 \n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(train_iter),\n",
    "    specials=['<pad>','<unk>'],\n",
    "    min_freq=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64edd609-f9c6-4ba1-836d-2f65148b12dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2222399a-6b85-41c8-aba6-d342e17c52e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建数据集 Dataloder\n",
    "train_dataset = to_map_style_dataset(train_iter)\n",
    "test_dataset = to_map_style_dataset(test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d891bf6-bfa8-44f3-b22f-54b1c69e54a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipline = lambda x:vocab(tokenizer(x))\n",
    "# 批数据处理 \n",
    "def collate_batch(batch):\n",
    "    label_list,text_list,offsets = [],[],[0]\n",
    "    for (_label,_text) in batch:\n",
    "        precess_text = torch.tensor(text_pipline(_text),dtype=torch.int64)\n",
    "        label_list.append(_label)\n",
    "        text_list.append(precess_text)\n",
    "        offsets.append(precess_text.size(0))\n",
    "    label_list = torch.tensor(label_list)\n",
    "    text_list = torch.cat(text_list)\n",
    "    offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "    return label_list,text_list,offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fcb46f15-ae25-4259-8666-6c871af525e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 64\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCHSIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCHSIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_batch\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a971973a-240d-49de-918a-d6962bf73bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for label,text,offset in train_dataloader:\n",
    "#     print(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7eebaca4-87be-42cc-9410-d3605cad68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)   # 获取此表大小\n",
    "embedding_dim = 100       # 定义词嵌入向量大小\n",
    "\n",
    "class TextClassificationModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size,embed_dim,num_class):\n",
    "        super(TextClassificationModel,self).__init__()\n",
    "        self.embedding = nn.EmbeddingBag(vocab_size,embed_dim,sparse=True)\n",
    "        \n",
    "        self.fc = nn.Linear(embed_dim,num_class)\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange,initrange)\n",
    "        self.fc.weight.data.uniform_(-initrange,initrange)\n",
    "        self.fc.bias.data.zero_()\n",
    "    \n",
    "    def forward(self,text,offsets):\n",
    "        embedded = self.embedding(text,offsets)\n",
    "        return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "90bc537e-547e-43c7-bbc3-b777c842884f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练的过程\n",
    "model = TextClassificationModel(vocab_size,embedding_dim,num_class)\n",
    "loss_fn = nn.CrossEntropyLoss()   # 分类问题的损失函数\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=0.1)\n",
    "exp_lr = lr_scheduler.StepLR(optimizer,step_size=20,gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "402b4447-8445-4aa2-ae29-502044dcf5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader):\n",
    "    total_acc,total_count,total_loss = 0,0,0\n",
    "    model.train()\n",
    "    for label,text,offsets in dataloader:\n",
    "        predicted_label = model(text,offsets)\n",
    "        loss = loss_fn(predicted_label,label)\n",
    "        \n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 记录器\n",
    "        with torch.no_grad():\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "            total_loss += loss.item() * label.size(0)\n",
    "        return total_loss/total_count,total_acc/total_count\n",
    "    \n",
    "def test(dataloader):\n",
    "    model.eval()\n",
    "    total_acc,total_count,total_loss = 0,0,0\n",
    "    with torch.no_grad():\n",
    "        for idx,(label,text,offsets) in enumerate(dataloader):\n",
    "            predicted_label = model(text,offsets)\n",
    "            loss = loss_fn(predicted_label,label)\n",
    "            total_loss += loss.item() * label.size(0)\n",
    "            total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "            total_count += label.size(0)\n",
    "    return total_loss/total_count,total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5faf0b2a-3997-477e-b1c6-ca3b59a92a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs,train_dl,test_dl):\n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    test_acc = []\n",
    "    test_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        start  =  time.time()\n",
    "        epoch_loss,epoch_acc = train(train_dl)\n",
    "        epoch_test_loss,epoch_test_acc = test(test_dl)\n",
    "        end = time.time()\n",
    "        times = end - start \n",
    "        train_acc.append(epoch_acc)\n",
    "        train_loss.append(epoch_loss)\n",
    "        test_acc.append(epoch_test_acc)\n",
    "        test_loss.append(epoch_test_loss)\n",
    "        exp_lr_scheduler.step()\n",
    "        print('训练epoch{},训练集损失值:{:.2f},训练集的准确率:{:.2f}%,测试集损失值:{:.2f},测试集的准确率:{:.2f}%,消耗时间：{:.2f}s'.\n",
    "              format(epoch+1,epoch_loss,epoch_acc*100,epoch_test_loss,epoch_test_acc*100,times))\n",
    "        \n",
    "    return train_loss,test_loss,train_acc,test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b6d50-7296-4f47-a6e0-ca17520c619f",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 50\n",
    "fit(epoch,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
