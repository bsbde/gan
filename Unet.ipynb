{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1420d8a5-a6ea-4aa5-b25f-74d33fad88f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils import data\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import glob \n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a402deb8-7fa2-4dc3-b891-895a7665e6b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/annotations/annotations/trimaps/Abyssinian_3.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16104\\684655054.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 数据展示\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mlabel_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/annotations/annotations/trimaps/Abyssinian_3.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mlabel_np_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./data/images/images/Abyssinian_3.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3090\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3091\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3092\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3093\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3094\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/annotations/annotations/trimaps/Abyssinian_3.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 数据展示 \n",
    "plt.figure(figsize=(12,8))\n",
    "label_img = Image.open('./data/annotations/annotations/trimaps/Abyssinian_3.png')\n",
    "label_np_img = np.array(label_img)\n",
    "img = Image.open('./data/images/images/Abyssinian_3.jpg')\n",
    "np_img = np.array(img)\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(np_img)\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(label_np_img,cmap='gray')\n",
    "\n",
    "# print('原始图像尺寸',np_img.shape)\n",
    "# print('标签图像尺寸',lab|el_np_img.shape)\n",
    "# print('标签图像分类值',np.unique(label_np_img))\n",
    "torch.squeeze(torch.tensor(label_np_img,dtype=torch.int64))-1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7a457ce-4063-4787-b831-1eab728e2003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7390"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 路径处理  \n",
    "images = glob.glob('data/images/images/*.jpg')\n",
    "annotations = [os.path.join('./data/annotations/annotations/trimaps',img_name.split('\\\\')[-1].replace('jpg','png')) for img_name in images]\n",
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d8feb88-01e8-43e2-804d-95e52caf3ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 数据集分割\n",
    "np.random.seed(42)\n",
    "index = np.random.permutation(len(images))\n",
    "images = np.array(images)[index]\n",
    "annotations = np.array(annotations)[index]\n",
    "\n",
    "sep = int(len(images)*0.8)\n",
    "train_images = images[:sep]\n",
    "train_label = annotations[:sep]\n",
    "\n",
    "test_images = images[sep:]\n",
    "test_label = annotations[sep:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e28a84d-3a90-4fa5-a305-6405c2bbdf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 制作训练作用的数据\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256,256)), # 修改尺寸\n",
    "    transforms.ToTensor()         # 张量\n",
    "]) \n",
    "\n",
    "# 数据处理工具\n",
    "\n",
    "class ox_dataset(data.Dataset):\n",
    "    def __init__(self,img_paths,anno_paths):\n",
    "        self.imgs = img_paths\n",
    "        self.annos = anno_paths\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        img = self.imgs[index]\n",
    "        anno = self.annos[index]\n",
    "        # 处理原始图形\n",
    "        '''\n",
    "        1. 读成数组\n",
    "        2. 转成 RGB 通道\n",
    "        3. 转成 张量 格式\n",
    "        '''\n",
    "        pil_img  = Image.open(img)\n",
    "        pil_img = pil_img.convert('RGB')\n",
    "        img_tensor = transform(pil_img)\n",
    "        \n",
    "        # 处理语义分割图像\n",
    "        '''\n",
    "        1. 读取\n",
    "        2. 重新定义为 256 * 256\n",
    "        3. 张量...\n",
    "        '''\n",
    "        pil_anno = Image.open(anno)\n",
    "        pil_anno = pil_anno.resize((256,256))\n",
    "        anno_tensor = torch.tensor(np.array(pil_anno),dtype=torch.int64)\n",
    "        \n",
    "        return img_tensor,torch.squeeze(anno_tensor) - 1 \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29fca7d4-b579-45e2-b3b5-adf13dd18e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 投喂数量\n",
    "BATCH_SIZE = 16\n",
    "# 数据 batch——size 打包\n",
    "train_dataset = ox_dataset(train_images,train_label)\n",
    "test_dataset = ox_dataset(test_images,test_label)\n",
    "\n",
    "train_dl = data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dl = data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# img_batch,anno_batch = next(iter(train_dl))\n",
    "# img = img_batch[0].permute(1,2,0).numpy()\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(img)\n",
    "\n",
    "# anno = anno_batch[0]\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63c16db8-5b01-4d10-a835-bc3e704f79da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征提取（下采样）\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels):\n",
    "        super(Downsample,self).__init__()\n",
    "        self.conv_relu = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels,out_channels,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "    \n",
    "    def forward(self,x,is_pool=True):\n",
    "        if is_pool:\n",
    "            x = self.pool(x)\n",
    "        x = self.conv_relu(x)\n",
    "        return x\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7ef3cbc-ceec-4dda-bd83-7f68b8fc9da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 上采样 （解码，还原）\n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self,channels):\n",
    "        super(Upsample,self).__init__()\n",
    "        self.conv_relu = nn.Sequential(\n",
    "            nn.Conv2d(2*channels,channels,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(channels,channels,kernel_size=3,padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "        \n",
    "        self.upconv_relu = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                channels,\n",
    "                channels//2,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.conv_relu(x)\n",
    "        x = self.upconv_relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd30a9c9-a110-4bbf-8c73-f2aa91163f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet_model,self).__init__()\n",
    "        # 特征提取组件的搭建完成\n",
    "        self.down1 = Downsample(3,64)\n",
    "        self.down2 = Downsample(64,128)\n",
    "        self.down3 = Downsample(128,256)\n",
    "        self.down4 = Downsample(256,512)\n",
    "        self.down5 = Downsample(512,1024)\n",
    "        \n",
    "        # 上采样\n",
    "        self.up = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                1024,\n",
    "                512,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.up1 = Upsample(512)\n",
    "        self.up2 = Upsample(256)\n",
    "        self.up3 = Upsample(128)\n",
    "        self.conv_2 = Downsample(128,64)\n",
    "        # 输出层\n",
    "        self.last = nn.Conv2d(64,3,kernel_size=1)\n",
    "    \n",
    "    # 前向传播\n",
    "    def forward(self,x):\n",
    "        x1 = self.down1(x,is_pool=False)\n",
    "        x2 = self.down2(x1)\n",
    "        x3 = self.down3(x2)\n",
    "        x4 = self.down4(x3)\n",
    "        x5 = self.down5(x4)\n",
    "        x5 = self.up(x5)\n",
    "        x5 = torch.cat([x4,x5],dim=1)\n",
    "        x5 = self.up1(x5)\n",
    "        x5 = torch.cat([x3,x5],dim=1)\n",
    "        x5 = self.up2(x5)\n",
    "        x5 = torch.cat([x2,x5],dim=1)\n",
    "        x5 = self.up3(x5)\n",
    "        x5 = torch.cat([x1,x5],dim=1)\n",
    "        x5 = self.conv_2(x5,is_pool=False)\n",
    "        x5 = self.last(x5)\n",
    "        \n",
    "        return x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c63517df-64cb-44c0-a6c0-0d8931473354",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet_model()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0005)\n",
    "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c590fc5-c3a0-4c0e-9971-8e4443f6c08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train(dataloader):\n",
    "    # 训练集的总数据\n",
    "    size = len(dataloader.dataset)\n",
    "    # 共计的 ***批数 batch 的个数\n",
    "    num_batches = len(dataloader)\n",
    "    # 损失值数据，识别数据（容器）\n",
    "    train_loss,correct = 0,0\n",
    "    # 训练模式\n",
    "    model.train()\n",
    "    for X,y in dataloader:\n",
    "        batch_start_time = time.time()\n",
    "        # 计算误差\n",
    "        X,y = X.to(device),y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred,y)\n",
    "        # 反向传递\n",
    "        optimizer.zero_grad()  # 固定操作（梯度归0）\n",
    "        loss.backward()\n",
    "        # 优化器\n",
    "        optimizer.step()\n",
    "        batch_end_time = time.time()\n",
    "        # 记录器\n",
    "        with torch.no_grad():\n",
    "            pred = torch.argmax(pred,dim=1)\n",
    "            # 汇总预测正确的‘像素个数’\n",
    "            correct += (pred == y).type(torch.float).sum().item()\n",
    "            train_loss += loss.item()\n",
    "            print('训练数据的预测对的像素个数为：{};每16个需消耗{}秒'.format(correct,round(batch_end_time-batch_start_time,2)))\n",
    "    train_loss /= num_batches\n",
    "    correct /= size * 256 * 256 # 除以总的样本数，每张图片有256 * 256个像素\n",
    "    return train_loss,correct\n",
    "\n",
    "# 定义测试函数\n",
    "def test():\n",
    "     # 训练集的总数据\n",
    "    size = len(dataloader.dataset)\n",
    "    # 共计的 ***批数 batch 的个数\n",
    "    num_batches = len(dataloader)\n",
    "    # 训练模式\n",
    "    model.eval()\n",
    "    test_loss,correct = 0,0\n",
    "    # 记录器\n",
    "    with torch.no_grad():\n",
    "        for X,y in dataloader:\n",
    "            X,y = X.to(device),y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss = loss_fn(pred,y).item()\n",
    "            pred = torch.argmax(pred,dim=1)\n",
    "            correct += (pred == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= num_batches\n",
    "    correct /= size * 256 * 256 # 除以总的样本数，每张图片有256 * 256个像素\n",
    "    return test_loss,correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93724784-7d18-4c3a-be8b-a2edc150e6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def fit(epochs,train_dl,test_dl):\n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    test_acc = []\n",
    "    test_loss = []\n",
    "    best_acc = 0.0\n",
    "    for epoch in range(epochs):\n",
    "        start  =  time.time()\n",
    "        epoch_loss,epoch_acc = train(dataloader=train_dl)\n",
    "        epoch_test_loss,epoch_test_acc = test(dataloader=test_dl)\n",
    "        end = time.time()\n",
    "        times = end - start \n",
    "        train_acc.append(epoch_acc)\n",
    "        train_loss.append(epoch_loss)\n",
    "        test_acc.append(epoch_test_acc)\n",
    "        test_loss.append(epoch_test_loss)\n",
    "        print('训练epoch{},训练集损失值:{:.2f},训练集的准确率:{:.2f}%,测试集损失值:{:.2f},测试集的准确率:{:.2f}%,消耗时间：{:.2f}s'.\n",
    "              format(epoch+1,epoch_loss,epoch_acc*100,epoch_test_loss,epoch_test_acc*100,times))   \n",
    "        if epoch_test_acc > best_acc:  # 如果当前的test_acc 高于best_acc 执行保存\n",
    "        best_acc = epoch_test_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    return train_loss,test_loss,train_acc,test_acc   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ae3fcd-33b0-42b7-ab7d-8925e03ab75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据的预测对的像素个数为：527134.0;每16个需消耗24.44秒\n",
      "训练数据的预测对的像素个数为：1182395.0;每16个需消耗25.28秒\n",
      "训练数据的预测对的像素个数为：1811977.0;每16个需消耗25.09秒\n"
     ]
    }
   ],
   "source": [
    "# 训练 \n",
    "fit(50,train_dl,test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce8bbac-02c9-4f51-9484-a05514d20e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'Unet_best.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
